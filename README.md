<p align="center">
  <img src="assets/logo.jpg" width="200"/>
</p>

English | [‰∏≠Êñá](README_zh.md) | [ÌïúÍµ≠Ïñ¥](README_ko.md) | [Êó•Êú¨Ë™û](README_ja.md)

[![GitHub stars](https://img.shields.io/github/stars/FoundationAgents/OpenManus?style=social)](https://github.com/FoundationAgents/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)
[![Demo](https://img.shields.io/badge/Demo-Hugging%20Face-yellow)]()
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15186407.svg)](https://doi.org/10.5281/zenodo.15186407)

# üëã OpenManus

Manus is incredible, We're also excited to introduce# FreEco.ai Platform (Enhanced OpenManus)

**AI-Powered Vegan Wellness Coach & Personal Organic Shopping Assistant**

> Built on OpenManus with advanced multi-model orchestration, planning, and multimodal capabilities.

---

## üå± About FreEco.ai

FreEco.ai combines cutting-edge AI agent technology with wellness coaching and intelligent shopping assistance for the vegan and organic lifestyle community. See [FREECO_AI_README.md](FREECO_AI_README.md) for the full FreEco.ai overview.

---

# OpenManus (Technical Documentation)-RL](https://github.com/OpenManus/OpenManus-RL), an open-source project dedicated to reinforcement learning (RL)- based (such as GRPO) tuning methods for LLM agents, developed collaboratively by researchers from UIUC and OpenManus.

## Project Demo

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## Installation

We provide two installation methods. Method 2 (using uv) is recommended for faster installation and better dependency management.

### Method 1: Using conda

1. Create a new conda environment:

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. Clone the repository:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

### Method 2: Using uv (Recommended)

1. Install uv (A fast Python package installer and resolver):

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. Clone the repository:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. Create a new virtual environment and activate it:

```bash
uv venv --python 3.12
source .venv/bin/activate  # On Unix/macOS
# Or on Windows:
# .venv\Scripts\activate
```

4. Install dependencies:

```bash
uv pip install -r requirements.txt
```

### Browser Automation Tool (Optional)
```bash
playwright install
```

## Configuration

OpenManus requires configuration for the LLM APIs it uses. Follow these steps to set up your configuration:

1. Create a `config.toml` file in the `config` directory (you can copy from the example):

```bash
cp config/config.example.toml config/config.toml
```

2. Edit `config/config.toml` to add your API keys and customize settings:

```toml
# Global LLM configuration
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # Replace with your actual API key
max_tokens = 4096
temperature = 0.0

# Optional configuration for specific LLM models and multi-model orchestration
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # Replace with your actual API key

# Example of multi-model orchestration:
# The LLMRouter will automatically select the model based on the agent's name (e.g., 'planning' or 'executor')
[llm.planning]
model = "claude-3-5-sonnet"
base_url = "https://api.anthropic.com/v1"
api_key = "sk-ant-..."

[llm.executor]
model = "qwen-max"
base_url = "https://api.qwen.com/v1"
api_key = "sk-qwen-..."

[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # Replace with your actual API key
```

## Advanced Planning Features

OpenManus now includes advanced planning capabilities that significantly improve task success rates and reasoning quality:

### 1. Multi-Model LLM Orchestration

Different tasks benefit from different models. OpenManus now supports routing different planning stages to specialized models:

- **Planning**: Use powerful reasoning models (e.g., Claude 3.5 Sonnet, GPT-4o) for complex task decomposition
- **Execution**: Use faster, cost-effective models (e.g., Qwen, GPT-4o-mini) for routine steps
- **Vision**: Use multimodal models for image/video tasks

Configure in `config.toml`:
```toml
[llm.planning]
model = "claude-3-5-sonnet"
base_url = "https://api.anthropic.com/v1"
api_key = "sk-ant-..."
temperature = 0.2  # Lower for more focused planning

[llm.executor]
model = "qwen-max"
base_url = "https://api.qwen.com/v1"
api_key = "sk-qwen-..."
temperature = 0.5
```

### 2. Tree-of-Thoughts Reasoning

For complex tasks, OpenManus can explore multiple planning approaches simultaneously:

- Generates 3-5 alternative strategies
- Evaluates each approach for feasibility, completeness, and efficiency
- Selects the best path based on cumulative quality scores
- Automatically prunes low-quality branches to focus resources

**Benefits**:
- 15-25% improvement on complex multi-step tasks
- Better handling of ambiguous requirements
- Automatic exploration of creative solutions

### 3. Self-Reflection and Continuous Learning

OpenManus learns from past executions to improve future planning:

- **Execution Memory**: Tracks success/failure patterns across tasks
- **Reflection Generation**: Automatically extracts lessons from failures
- **Plan Improvement**: Incorporates past learnings into new plans
- **Confidence Scoring**: Prioritizes high-confidence insights

**Example Reflection**:
```
[ERROR_HANDLING] When task involves file I/O, always check file exists first
Confidence: 0.85 (based on 5 past failures)
```

### 4. Enhanced Prompt Engineering

OpenManus uses advanced prompting strategies based on research and production experience:

- **Structured Decomposition**: Clear dependencies and success criteria
- **Error Anticipation**: Explicit failure handling at each step
- **Verification Steps**: Built-in validation after critical actions
- **Role-Playing**: Domain-specific expertise in planning

**Impact**: 20-30% improvement in task success rate (70-85% ‚Üí 95%+)

### Configuration

Advanced planning is enabled by default. To customize:

```python
# In your code
from app.flow.planning import PlanningFlow
from app.reasoning import TreeOfThoughts, ReflectionEngine

flow = PlanningFlow(
    agents=my_agents,
    use_advanced_planning=True,  # Enable advanced features
)

# The flow will automatically:
# - Use reflection-enhanced planning when execution history exists
# - Fall back to Tree-of-Thoughts for new/complex tasks
# - Apply the best model for each planning stage
```

### Monitoring and Debugging

Check planning quality with built-in statistics:

```python
# Get Tree-of-Thoughts stats
if flow.tree_of_thoughts:
    stats = flow.tree_of_thoughts.get_tree_stats()
    print(f"Explored {stats['total_nodes']} alternatives")
    print(f"Average score: {stats['avg_score']:.2f}")

# Get Reflection engine stats
reflection_stats = flow.reflection_engine.get_stats()
print(f"Success rate: {reflection_stats['success_rate']:.1%}")
print(f"Total reflections: {reflection_stats['total_reflections']}")
```

## üõ†Ô∏è Enhancement #4: Multimodal Tools & Integrations

OpenManus now includes powerful tools for YouTube, Knowledge Management, Notion, and CRM integration.

### YouTube Transcript Tool

Extract transcripts from YouTube videos and add them to your knowledge base:

```python
from app.tool.youtube_transcript import YouTubeTranscriptTool

tool = YouTubeTranscriptTool()

# Get transcript
result = await tool.execute(
    action="get_transcript",
    video_id="dQw4w9WgXcQ",
    include_metadata=True
)

print(result.output['transcript'])
print(result.output['metadata']['title'])
```

### Knowledge Base Tool

Vector database for Retrieval-Augmented Generation (RAG):

```python
from app.tool.knowledge_base import KnowledgeBaseTool

kb = KnowledgeBaseTool()

# Add knowledge
await kb.execute(
    action="add",
    content="OpenManus is an open-source agentic AI framework.",
    title="OpenManus Overview",
    source="manual"
)

# Semantic search
results = await kb.execute(
    action="search",
    query="What is OpenManus?",
    top_k=5
)
```

**Features**:
- Semantic search using OpenAI embeddings
- Automatic chunking for long documents
- Persistent storage with FAISS
- Metadata filtering and organization

**Requirements**: `pip install langchain openai faiss-cpu`

### Notion Integration Tool

Read, write, and manage Notion pages and databases:

```python
from app.tool.notion_integration import NotionTool

tool = NotionTool()

# Create page
await tool.execute(
    action="create_page",
    database_id="your-database-id",
    title="Meeting Notes",
    content="# Key Points\n- Discussed roadmap\n- Next steps"
)

# Search workspace
results = await tool.execute(
    action="search",
    query="project plan"
)

# Add to knowledge base
await tool.execute(
    action="add_to_knowledge",
    page_id="your-page-id"
)
```

**Requirements**: 
- `pip install notion-client`
- Set `NOTION_API_KEY` environment variable

### CRM Integration Tool

Manage contacts and deals across multiple CRM platforms:

```python
from app.tool.crm_integration import CRMTool

tool = CRMTool()

# Create contact
await tool.execute(
    action="create_contact",
    name="John Doe",
    email="john@example.com",
    company="Acme Corp"
)

# Search contacts
results = await tool.execute(
    action="search_contacts",
    search_query="john"
)

# Create deal
await tool.execute(
    action="create_deal",
    deal_name="Q1 Contract",
    deal_value=50000,
    contact_id="contact-id"
)

# Get AI insights
insights = await tool.execute(
    action="get_insights",
    context="pipeline"
)
```

**Supported CRMs**:
- Twenty CRM (open-source, self-hosted)
- HubSpot
- Salesforce
- Pipedrive
- KeyCRM (Ukrainian CRM platform)

**Requirements**: 
- `pip install aiohttp`
- Set `CRM_TYPE` (options: "twenty", "hubspot", "salesforce", "pipedrive", "keycrm")
- Set corresponding API key:
  - `TWENTY_API_KEY` for Twenty CRM
  - `HUBSPOT_API_KEY` for HubSpot
  - `SALESFORCE_ACCESS_TOKEN` for Salesforce
  - `PIPEDRIVE_API_TOKEN` for Pipedrive
  - `KEYCRM_API_KEY` for KeyCRM

### Example Workflow: YouTube ‚Üí Knowledge ‚Üí Notion

```python
# 1. Get YouTube transcript
yt_result = await youtube_tool.execute(
    action="get_transcript",
    video_id="video-id",
    include_metadata=True
)

# 2. Add to knowledge base
kb_result = await kb_tool.execute(
    action="add",
    content=yt_result.output['transcript'],
    title=yt_result.output['metadata']['title'],
    source=f"youtube:{yt_result.output['video_id']}"
)

# 3. Create Notion page with summary
await notion_tool.execute(
    action="create_page",
    database_id="your-db-id",
    title=f"Video Notes: {yt_result.output['metadata']['title']}",
    content=yt_result.output['transcript'][:2000]  # First 2000 chars
)
```

**Impact**: Expands addressable task types by 50%+, enables multimodal and real-world integrations.

## Quick Start

One line for run OpenManus:

```bash
python main.py
```

Then input your idea via terminal!

For MCP tool version, you can run:
```bash
python run_mcp.py
```

For unstable multi-agent version, you also can run:

```bash
python run_flow.py
```

### Custom Adding Multiple Agents

Currently, besides the general OpenManus Agent, we have also integrated the DataAnalysis Agent, which is suitable for data analysis and data visualization tasks. You can add this agent to `run_flow` in `config.toml`.

```toml
# Optional configuration for run-flow
[runflow]
use_data_analysis_agent = true     # Disabled by default, change to true to activate
```
In addition, you need to install the relevant dependencies to ensure the agent runs properly: [Detailed Installation Guide](app/tool/chart_visualization/README.md##Installation)

## How to contribute

We welcome any friendly suggestions and helpful contributions! Just create issues or submit pull requests.

Or contact @mannaandpoem via üìßemail: mannaandpoem@gmail.com

**Note**: Before submitting a pull request, please use the pre-commit tool to check your changes. Run `pre-commit run --all-files` to execute the checks.

## Community Group
Join our networking group on Feishu and share your experience with other developers!

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus ‰∫§ÊµÅÁæ§" width="300" />
</div>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=FoundationAgents/OpenManus&type=Date)](https://star-history.com/#FoundationAgents/OpenManus&Date)

## Sponsors
Thanks to [PPIO](https://ppinfra.com/user/register?invited_by=OCPKCN&utm_source=github_openmanus&utm_medium=github_readme&utm_campaign=link) for computing source support.
> PPIO: The most affordable and easily-integrated MaaS and GPU cloud solution.


## Acknowledgement

Thanks to [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo), [browser-use](https://github.com/browser-use/browser-use) and [crawl4ai](https://github.com/unclecode/crawl4ai) for providing basic support for this project!

Additionally, we are grateful to [AAAJ](https://github.com/metauto-ai/agent-as-a-judge), [MetaGPT](https://github.com/geekan/MetaGPT), [OpenHands](https://github.com/All-Hands-AI/OpenHands) and [SWE-agent](https://github.com/SWE-agent/SWE-agent).

We also thank stepfun(Èò∂Ë∑ÉÊòüËæ∞) for supporting our Hugging Face demo space.

OpenManus is built by contributors from MetaGPT. Huge thanks to this agent community!

## Cite
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong and Sheng Fan and Xiao Tang},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.15186407},
  url = {https://doi.org/10.5281/zenodo.15186407},
}
```
